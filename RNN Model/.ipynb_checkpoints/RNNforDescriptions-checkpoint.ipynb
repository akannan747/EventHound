{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('event_data4.csv')\n",
    "descriptions = ''\n",
    "\n",
    "for description in event_data[' description']:\n",
    "    description = re.sub(\"[^a-zA-Z]\", \" \", description)\n",
    "    description = description.lower().split()\n",
    "    for text in description:\n",
    "        descriptions += text + ' '\n",
    "    descriptions += '\\n'\n",
    "\n",
    "text = descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "b\n",
      "'for bottle service please email us at booking add details saturday night rooftop party at cantina rooftop bar lounge w th st new york ny new york city nightclub music by special guest dj doors open at pm ladies free till am gents table reservation for bottle service b day party or any event please send us an email to booking free admission on iclubnyc list only and over with proper id final entrence is upto the doorman discretn must show tickets or say iclubnyc list at the door to get right in st'\n",
      "'rict dress code policy gentlemen shoes button down shirts and jeans are acceptable no baggy attire sneakers boots or hats are allowed ladies heels classy look please contact us www iclubnyc com boat party cruise \\nsuite life fridays hosted by big tigger free til w rsvp furious peachtree road atlanta ga \\njoin us this saturday for the rooftop day party experience in the city of atlanta indoor outdoor rooftop is heated and covered doors open at pm everyone free till w rsvp early arrival is suggested '\n",
      "'dress code enforced text or call for tables or more info powered by vonthepromoter after party at the all new revel of west midtown \\nyour free galleries ticket will allow you unlimited access on the day of your visit to all the displays open in our permanent galleries and the wharf heritage centre you can also access our popular cabinet of curiosities when programmed suitable for all ages and our mini mariners play space designed especially for children under age to access everything the mueum ha'\n",
      "'s to offer including special exhibitions and our fleet of vessels please purchase a big ticket ticket is valid any day and for months from date of purchase \\nsuite life fridays hosted by big tigger free til w rsvp furious peachtree road atlanta ga \\nfloristeria un associazione culturale attenta ai temi sociali presenta tierra viva un edizione dedicata al cambiamento e al futuro \\njoin us this saturday at the all new million dollar venue revel of west midtown fellas free till w rsvp ladies free till '\n",
      "'text or call free bday parties sections or more info follow revelatlanta on instagram for all of our weekly events powered by vonthepromoter \\njoin four freedoms state park in celebrating the roosevelt island community cherry blossom festival featuring traditional and modern japanese performances and cultural fair and special performances at the park schedule of events am tea ceremony southpoint park community picnics food vendors west promenade across from cornell tech am pm japanese cultural fai'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 500\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])\n",
    "    \n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size \n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    import functools\n",
    "    rnn = functools.partial(tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
    "    \n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dense(vocab_size)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 500, 28)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       3.3337374\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/396 [..............................] - ETA: 1:49:31 - loss: 3.0800"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1 #tune up for better results\n",
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"Tigger \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
